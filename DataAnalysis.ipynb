{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0N12-6GU0UwR"
   },
   "source": [
    "# Data Analysis\n",
    "Initial imports for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kHZWSLB0UwT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "import numpy as np\n",
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcEon1W40Uwb"
   },
   "source": [
    "The data is available [here](https://figshare.com/projects/Wikipedia_Talk/16731).\n",
    "First, let's see how this data is arranged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bstL8tI-0Uwd",
    "outputId": "0fc5384b-8995-49dc-d941-fe02e0a6a431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115864, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Those are the dictionary definitions of the terms ``insurance`` and ``ensurance`` as properly applied to ``destruction``.  If you don't understand that, f...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``standard model`` is itself less NPOV than I think we'd prefer...NEWLINE_TOKENNEWLINE_TOKEN:: if it's ``new-age speak`` then a lot of old-age people speak i...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the situation as of March 2002 was such: NEWLINE_TOKENA Saudi proposal of Land for Peace AND recognition by ALL arab countries was made. The day the propos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL, both of which I read quite a while ago, thanks. I really liked the bit w...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                        comment  \\\n",
       "rev_id                                                                                                                                                                                                            \n",
       "37675   `-NEWLINE_TOKENThis is not ``creative``.  Those are the dictionary definitions of the terms ``insurance`` and ``ensurance`` as properly applied to ``destruction``.  If you don't understand that, f...   \n",
       "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``standard model`` is itself less NPOV than I think we'd prefer...NEWLINE_TOKENNEWLINE_TOKEN:: if it's ``new-age speak`` then a lot of old-age people speak i...   \n",
       "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the situation as of March 2002 was such: NEWLINE_TOKENA Saudi proposal of Land for Peace AND recognition by ALL arab countries was made. The day the propos...   \n",
       "89320    Next, maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL, both of which I read quite a while ago, thanks. I really liked the bit w...   \n",
       "93890                                                                                                                                                                      This page will need disambiguation.    \n",
       "\n",
       "        year  logged_in       ns  sample  split  \n",
       "rev_id                                           \n",
       "37675   2002       True  article  random  train  \n",
       "44816   2002       True  article  random  train  \n",
       "49851   2002       True  article  random  train  \n",
       "89320   2002       True  article  random    dev  \n",
       "93890   2002       True  article  random  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load comments\n",
    "comments = pd.read_csv('aggression_annotated_comments.tsv',sep='\\t', index_col=0)\n",
    "print(comments.shape)\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpykJ-Qt0Uwo"
   },
   "source": [
    "Now, that we know how our data is arranged we can start to filter and clean it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ff-LY8Ic0Uwr"
   },
   "source": [
    "\n",
    "# Data Cleaning\n",
    "We are going to use the column `comment` from the loaded DataFrame. Additionally, as we can see, the new line character is represented by the `NEWLINE_TOKEN`. Going furher I found that the following  tokens are present:\n",
    "- `NEWLINE_TOKEN`\n",
    "- `NEWLINE;_TOKEN`\n",
    "- `TAB_TOKEN`\n",
    "Additionally, since we are using this data for a **classification** task, the words have far more importance than the punctuation. Therefore, we will also remove the punctuation \n",
    "Let's **remove** all unwanted information from the `comments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJjGe5KW0Uws",
    "outputId": "1c37228e-2366-411a-96c7-aa51ec583935"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less NPOV than I think wed prefer if its newage speak then a lot of oldage people speak it  Karl Popper the Pope etc  heres Karl Poppers view of this The cleares...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>True or false the situation as of March 2002 was such A Saudi proposal of Land for Peace AND recognition by ALL arab countries was made The day the proposal was to be made formal by the Arab Leagu...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL both of which I read quite a while ago thanks I really liked the bit where...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                        comment  \\\n",
       "rev_id                                                                                                                                                                                                            \n",
       "37675   This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...   \n",
       "44816    the term standard model is itself less NPOV than I think wed prefer if its newage speak then a lot of oldage people speak it  Karl Popper the Pope etc  heres Karl Poppers view of this The cleares...   \n",
       "49851   True or false the situation as of March 2002 was such A Saudi proposal of Land for Peace AND recognition by ALL arab countries was made The day the proposal was to be made formal by the Arab Leagu...   \n",
       "89320    Next maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL both of which I read quite a while ago thanks I really liked the bit where...   \n",
       "93890                                                                                                                                                                       This page will need disambiguation    \n",
       "\n",
       "        year  logged_in       ns  sample  split  \n",
       "rev_id                                           \n",
       "37675   2002       True  article  random  train  \n",
       "44816   2002       True  article  random  train  \n",
       "49851   2002       True  article  random  train  \n",
       "89320   2002       True  article  random    dev  \n",
       "93890   2002       True  article  random  train  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Tokens\n",
    "comments['comment'] = comments.comment.str.replace('NEWLINE_TOKEN', '')\n",
    "comments['comment'] = comments.comment.str.replace('NEWLINE;_TOKEN', '')\n",
    "comments['comment'] = comments.comment.str.replace('TAB_TOKEN', '')\n",
    "\n",
    "# Remove Punctuation\n",
    "comments['comment'] = comments.comment.str.replace('[{}]'.format(string.punctuation), '')\n",
    "\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZZEigWE0Uw2"
   },
   "source": [
    "Alright, our data looks way cleaner now. However, our data is not complete because the labels is missing. Then, we still need to combine the other file `aggression_annotations.tsv` that contains the labels for each comment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TH6O7I2o0Uw6",
    "outputId": "676414f0-74cb-42df-de96-db81597999fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1365217, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>aggression</th>\n",
       "      <th>aggression_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>1362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37675</td>\n",
       "      <td>2408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37675</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37675</td>\n",
       "      <td>1439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37675</td>\n",
       "      <td>170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37675</td>\n",
       "      <td>176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37675</td>\n",
       "      <td>481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37675</td>\n",
       "      <td>487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>37675</td>\n",
       "      <td>578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37675</td>\n",
       "      <td>1127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id  worker_id  aggression  aggression_score\n",
       "0   37675       1362         1.0              -1.0\n",
       "1   37675       2408         0.0               1.0\n",
       "2   37675       1493         0.0               0.0\n",
       "3   37675       1439         0.0               0.0\n",
       "4   37675        170         0.0               0.0\n",
       "5   37675        176         0.0               0.0\n",
       "6   37675        481         0.0               0.0\n",
       "7   37675        487         0.0               0.0\n",
       "8   37675        578         0.0               0.0\n",
       "9   37675       1127         0.0               0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.read_csv('aggression_annotations.tsv', sep='\\t')\n",
    "print(annotations.shape)\n",
    "annotations.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUmO-7mm0UxE"
   },
   "source": [
    "Hmm, seems that the each comment is evaluated by a *worker* that gives a score of **0 or 1** for the comment. So let's average the score for each _worker_ and discretize the result with a **0.5 threshold**. Finally, we join the result in the `comments` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiwCLLDj0UxF",
    "outputId": "8e5dcfa0-8a9c-4a5f-d7b0-b3ecc6cc48fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>aggression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>the term standard model is itself less NPOV than I think wed prefer if its newage speak then a lot of oldage people speak it  Karl Popper the Pope etc  heres Karl Poppers view of this The cleares...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>True or false the situation as of March 2002 was such A Saudi proposal of Land for Peace AND recognition by ALL arab countries was made The day the proposal was to be made formal by the Arab Leagu...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL both of which I read quite a while ago thanks I really liked the bit where...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                        comment  \\\n",
       "rev_id                                                                                                                                                                                                            \n",
       "37675   This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...   \n",
       "44816    the term standard model is itself less NPOV than I think wed prefer if its newage speak then a lot of oldage people speak it  Karl Popper the Pope etc  heres Karl Poppers view of this The cleares...   \n",
       "49851   True or false the situation as of March 2002 was such A Saudi proposal of Land for Peace AND recognition by ALL arab countries was made The day the proposal was to be made formal by the Arab Leagu...   \n",
       "89320    Next maybe you could work on being less condescending with your suggestions about reading the naming conventions and FDL both of which I read quite a while ago thanks I really liked the bit where...   \n",
       "93890                                                                                                                                                                       This page will need disambiguation    \n",
       "\n",
       "        year  logged_in       ns  sample  split  aggression  \n",
       "rev_id                                                       \n",
       "37675   2002       True  article  random  train       False  \n",
       "44816   2002       True  article  random  train       False  \n",
       "49851   2002       True  article  random  train       False  \n",
       "89320   2002       True  article  random    dev       False  \n",
       "93890   2002       True  article  random  train       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = annotations.groupby('rev_id').aggression.mean() > 0.5\n",
    "comments['aggression'] = labels\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPscWJ6g0UxL"
   },
   "source": [
    "Generally, it is a good idea to see some comments labeled *aggresive* to see if it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnJl8Y980UxM",
    "outputId": "e1a33507-1ae8-4055-fd72-5ca2174f80d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694840</th>\n",
       "      <td>Click on my Annoying Users link I guess Massachusetts is a republic then  Defending facts against the lies of determined zealots seems to be a particular stickingplace for Wikipedia    0258 Feb 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801279</th>\n",
       "      <td>Iraq is not good    USA is bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450441</th>\n",
       "      <td>Buddha  Some suggest that victims should be referred to additional resources and made aware of their rights under policy and lawThats an incredibly silly way to phrase that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702703</th>\n",
       "      <td>fuck off you little asshole If you want to talk to me as a human start showing some fear the way humans act around other humans because if you continue your beligerant campaign i will cross anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632658</th>\n",
       "      <td>i have a dick its bigger than yours hahaha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         comment\n",
       "rev_id                                                                                                                                                                                                          \n",
       "694840   Click on my Annoying Users link I guess Massachusetts is a republic then  Defending facts against the lies of determined zealots seems to be a particular stickingplace for Wikipedia    0258 Feb 21...\n",
       "801279                                                                                                                                                                           Iraq is not good    USA is bad \n",
       "1450441                           Buddha  Some suggest that victims should be referred to additional resources and made aware of their rights under policy and lawThats an incredibly silly way to phrase that  \n",
       "2702703  fuck off you little asshole If you want to talk to me as a human start showing some fear the way humans act around other humans because if you continue your beligerant campaign i will cross anothe...\n",
       "4632658                                                                                                                                                               i have a dick its bigger than yours hahaha"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See 5 agressive comments\n",
    "comments.comment[comments.aggression].to_frame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XHV8o9nP0UxU"
   },
   "source": [
    "Well, that is enough... It seems to be accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x82pB5rK0UxZ"
   },
   "source": [
    "Than the only thing remaining is perform the same task to the other datasets for **attack** and **toxicity**. A small functions was created to facilitate this task. All data was store in the variables `attack`, `aggression` and `toxicity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k7wlZzMp0Uxa"
   },
   "outputs": [],
   "source": [
    "def clean_data(comments_file, annotations_file, metric_column):\n",
    "    \"\"\"\n",
    "    Function to load the data from the dataset, clean and prepare it for ML algorithms.\n",
    "    \n",
    "    Args:\n",
    "        comments_file: File with the comments data.\n",
    "        annotations_file: File wit the annotations data.\n",
    "        metric_columns: The columns name that represents the metric for the specific\n",
    "        kind of bad behaviour.\n",
    "        \n",
    "    Returns\n",
    "        A Pandas DataFrame with the comments cleaned and a columns named `metric_column`\n",
    "        with the label data.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    comments = pd.read_csv(comments_file, sep='\\t', index_col=0)\n",
    "    annotations = pd.read_csv(annotations_file, sep='\\t', index_col=0)\n",
    "    \n",
    "    # Clean comments\n",
    "    comments['comment'] = comments.comment.str.replace('NEWLINE_TOKEN', '')\n",
    "    comments['comment'] = comments.comment.str.replace('NEWLINE;_TOKEN', '')\n",
    "    comments['comment'] = comments.comment.str.replace('TAB_TOKEN', '')\n",
    "    comments['comment'] = comments.comment.str.replace('[{}]'.format(string.punctuation), '')\n",
    "    \n",
    "    # Created the label\n",
    "    labels = annotations.groupby('rev_id')[metric_column].mean() > 0.5\n",
    "    comments[metric_column] = labels\n",
    "    \n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96xSlIV90Uxg",
    "outputId": "e12bd805-a1fb-4303-f58f-421ed5ff36d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\lib\\arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "aggression = clean_data('aggression_annotated_comments.tsv', 'aggression_annotations.tsv', 'aggression')\n",
    "attack = clean_data('attack_annotated_comments.tsv', 'attack_annotations.tsv', 'attack')\n",
    "toxicity = clean_data('toxicity_annotated_comments.tsv', 'toxicity_annotations.tsv', 'toxicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKyyPq7w0Uxn"
   },
   "source": [
    "Apparently, the same comments were used for the **Attack** and **Aggression** Datasets. However the **Toxicity** data has different values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ysuaffwj0Uxo",
    "outputId": "520f2514-6c8a-49db-f5c3-735481387e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Aggression and Attack shape: (115864, 7)\n",
      "Toxicity shape: (159686, 7)\n"
     ]
    }
   ],
   "source": [
    "# Check for equivalent comments\n",
    "print(aggression.comment.equals(attack.comment))\n",
    "print(\"Aggression and Attack shape: {}\".format(aggression.shape))\n",
    "print(\"Toxicity shape: {}\".format(toxicity.shape))\n",
    "assert aggression.shape == attack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyf1uc_N0Uxt"
   },
   "source": [
    "We could try to combine all data in only one dataset. This way, we result in a dataset for a multi-class classification. Nonetheless, the data willbe significantly reduce to the number of comments present in all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Srvw2b5Z0Uxu",
    "outputId": "b127e9a6-f73e-4024-8ec5-43be1357305f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77972\n"
     ]
    }
   ],
   "source": [
    "# number of comments common to all data\n",
    "print(aggression.index.isin(toxicity.index).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbVcJudm0Ux5",
    "outputId": "9e9a4331-22b1-4672-fb43-be2883ddf242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77972, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>aggression</th>\n",
       "      <th>attack</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675.0</th>\n",
       "      <td>This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297866.0</th>\n",
       "      <td>Ummm The article uses imperial measurements not SI ones Some translation is apparently in order  Anders Törlind</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360594.0</th>\n",
       "      <td>I disagree I would leave it out of the introductory part since its population which changes every census is not nearly as fundamental as the fact that it is in a particular state its county seat i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377054.0</th>\n",
       "      <td>I dont know where you got the idea that Mt Airys in 4 counties Its only in two Were you the one Tokerboy who added two counties to the two Id listed when I put it into the Frederick County article...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661509.0</th>\n",
       "      <td>MarcusAureliusWhy exactly was this user banned</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                          comment  \\\n",
       "rev_id                                                                                                                                                                                                              \n",
       "37675.0   This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...   \n",
       "297866.0                                                                                          Ummm The article uses imperial measurements not SI ones Some translation is apparently in order  Anders Törlind   \n",
       "360594.0  I disagree I would leave it out of the introductory part since its population which changes every census is not nearly as fundamental as the fact that it is in a particular state its county seat i...   \n",
       "377054.0  I dont know where you got the idea that Mt Airys in 4 counties Its only in two Were you the one Tokerboy who added two counties to the two Id listed when I put it into the Frederick County article...   \n",
       "661509.0                                                                                                                                                          MarcusAureliusWhy exactly was this user banned    \n",
       "\n",
       "          aggression  attack  toxicity  \n",
       "rev_id                                  \n",
       "37675.0        False   False     False  \n",
       "297866.0       False   False     False  \n",
       "360594.0       False   False     False  \n",
       "377054.0       False   False     False  \n",
       "661509.0       False   False     False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine result in comments df\n",
    "combined_data = aggression\n",
    "combined_data['attack'] = attack.attack\n",
    "\n",
    "combined_data = pd.merge(combined_data[['comment', 'aggression', 'attack']],\n",
    "                    toxicity[['comment', 'toxicity']], how='inner', \n",
    "                    left_index=True, right_index=True, on='comment')\n",
    "print(combined_data.shape)\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1399,
     "status": "error",
     "timestamp": 1548888329380,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "v-CAg7z10UyD",
    "outputId": "bd9ef1bc-f1cc-4838-f730-da0522c38acf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1502668.0</th>\n",
       "      <td>BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163533.0</th>\n",
       "      <td>new yorki got 100 gunsa hundred clipsnigga im from new yorknew york ja rule ft fat joe and jadakiss  new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8357601.0</th>\n",
       "      <td>You abused your authority by blocking me improperly then you refused to apologize “So tough” then you tried to bully me Do not revert like you have been ever again Understood and now you are threa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8855554.0</th>\n",
       "      <td>I am not user 1682099734 On what basis are you acusing me of being that user Please answer the very simple question Is the phrase antiIslamic cut and past sic troll a personal attack or is  it no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373666.0</th>\n",
       "      <td>Sandnigger referring to the fact that they live in the desert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                           comment\n",
       "rev_id                                                                                                                                                                                                            \n",
       "1502668.0  BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOBS BOOB...\n",
       "8163533.0                                                                                            new yorki got 100 gunsa hundred clipsnigga im from new yorknew york ja rule ft fat joe and jadakiss  new york\n",
       "8357601.0  You abused your authority by blocking me improperly then you refused to apologize “So tough” then you tried to bully me Do not revert like you have been ever again Understood and now you are threa...\n",
       "8855554.0   I am not user 1682099734 On what basis are you acusing me of being that user Please answer the very simple question Is the phrase antiIslamic cut and past sic troll a personal attack or is  it no...\n",
       "9373666.0                                                                                                                                            Sandnigger referring to the fact that they live in the desert"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some only toxic comments\n",
    "combined_data.comment[(combined_data.aggression == False) &\n",
    "                      (combined_data.attack == False) &\n",
    "                      (combined_data.toxicity == True)].to_frame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DDNmeBjL0UyK"
   },
   "source": [
    "## Data Unbalance\n",
    "ML models performance are know to be reduced by data unbalance. Let's see how our unbalance is our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kerb3J5W0UyM",
    "outputId": "125e3701-047a-4d85-d4fe-5b0a7831dd5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Aggression: 14782. Data %: 0.1275806117517089\n",
      "Total Attack: 13590. Data %: 0.11729268797900988\n",
      "Total Toxicity: 15362. Data %: 0.09620129504151897\n"
     ]
    }
   ],
   "source": [
    "# Data unbalance\n",
    "print(\"Total Aggression: {}. Data %: {}\".format(aggression.aggression.sum(), aggression.aggression.sum() / aggression.aggression.count()))\n",
    "print(\"Total Attack: {}. Data %: {}\".format(attack.attack.sum(), attack.attack.sum() / attack.attack.count()))\n",
    "print(\"Total Toxicity: {}. Data %: {}\".format(toxicity.toxicity.sum(), toxicity.toxicity.sum() / toxicity.toxicity.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gXTeVOLu0UyW"
   },
   "source": [
    "We can see that for each class approximately 10% of the data was classified as some of the classes. And the classes seems pretty balanced. Finally, we can save the final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLOpCmc50UyX",
    "outputId": "58e36d60-67f3-4db2-f6ff-603439cac157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Aggression: 13843. Data %: 0.17753809059662443\n",
      "Total Attack: 12784. Data %: 0.16395629200225723\n",
      "Total Toxicity: 13694. Data %: 0.1756271482070487\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Aggression: {}. Data %: {}\".format(combined_data.aggression.sum(),\n",
    "                                                combined_data.aggression.sum() / combined_data.aggression.count()))\n",
    "print(\"Total Attack: {}. Data %: {}\".format(combined_data.attack.sum(),\n",
    "                                            combined_data.attack.sum() / combined_data.attack.count()))\n",
    "print(\"Total Toxicity: {}. Data %: {}\".format(combined_data.toxicity.sum(),\n",
    "                                              combined_data.toxicity.sum() / combined_data.toxicity.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0Ys0Yiu0Uyb"
   },
   "source": [
    "Here, each class represent approximately 16% of the data. As we can see, the data has some good balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8i1vV2gq0Uyd"
   },
   "outputs": [],
   "source": [
    "# Saves individual and combined datasets\n",
    "aggression[['comment', 'aggression']].to_csv('aggression.csv')\n",
    "attack[['comment', 'attack']].to_csv('attack.csv')\n",
    "toxicity[['comment', 'toxicity']].to_csv('toxicity.csv')\n",
    "\n",
    "combined_data.to_csv('combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j8jbwYiL0Uyh"
   },
   "source": [
    "# Prepare Data for Machine Learning Models\n",
    "\n",
    "First, let's use a pre-trained **Word2Vec Embedding Model** to see if we can obtain reasonable result with this simplistic model. Staring by importing the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28751,
     "status": "ok",
     "timestamp": 1548881998549,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "CT5UA55w0Uyh",
    "outputId": "37138ffd-9d6d-42dc-887b-28015f28fe3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Google colab, searching for local files.\n"
     ]
    }
   ],
   "source": [
    "# Google colab for training\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"In Google colab, mouting drive for data.\")\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    print(\"Not in Google colab, searching for local files.\")\n",
    "    IN_COLAB = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1088
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37121,
     "status": "ok",
     "timestamp": 1548882042298,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "EmYq_4g509Rm",
    "outputId": "2f329785-89cf-464f-f873-9bb10290e19a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\program files\\python36\\lib\\site-packages (2.0.18)\n",
      "Requirement already satisfied: torch in c:\\program files\\python36\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python36\\lib\\site-packages (4.28.1)\n",
      "Requirement already satisfied: regex==2018.01.10 in c:\\program files\\python36\\lib\\site-packages (from spacy) (2018.1.10)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\program files\\python36\\lib\\site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in c:\\program files\\python36\\lib\\site-packages (from spacy) (6.12.1)\n",
      "Requirement already satisfied: ujson>=1.35 in c:\\program files\\python36\\lib\\site-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\program files\\python36\\lib\\site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\program files\\python36\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in c:\\program files\\python36\\lib\\site-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\program files\\python36\\lib\\site-packages (from spacy) (1.15.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\program files\\python36\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\program files\\python36\\lib\\site-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in c:\\program files\\python36\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<0.4.4 in c:\\program files\\python36\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in c:\\users\\nando\\appdata\\roaming\\python\\python36\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in c:\\program files\\python36\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.0)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in c:\\program files\\python36\\lib\\site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
      "Requirement already satisfied: pyreadline>=1.7.1 in c:\\program files\\python36\\lib\\site-packages (from dill<0.3,>=0.2->spacy) (2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2017.7.27.1)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\program files\\python36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\program files\\python36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\program files\\python36\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\program files\\python36\\lib\\site-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Compatibility error\n",
      "    No compatible model found for ''en_core_web_md'' (spaCy v2.0.18).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy torch tqdm\n",
    "!python -m spacy download 'en_core_web_md'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2179,
     "status": "ok",
     "timestamp": 1548888283698,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "hAvKdmaN05nk",
    "outputId": "2d40a430-c0d2-4801-e7d8-4af07d20ac14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>aggression</th>\n",
       "      <th>attack</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675.0</th>\n",
       "      <td>This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297866.0</th>\n",
       "      <td>Ummm The article uses imperial measurements not SI ones Some translation is apparently in order  Anders Törlind</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360594.0</th>\n",
       "      <td>I disagree I would leave it out of the introductory part since its population which changes every census is not nearly as fundamental as the fact that it is in a particular state its county seat i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377054.0</th>\n",
       "      <td>I dont know where you got the idea that Mt Airys in 4 counties Its only in two Were you the one Tokerboy who added two counties to the two Id listed when I put it into the Frederick County article...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661509.0</th>\n",
       "      <td>MarcusAureliusWhy exactly was this user banned</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                          comment  \\\n",
       "rev_id                                                                                                                                                                                                              \n",
       "37675.0   This is not creative  Those are the dictionary definitions of the terms insurance and ensurance as properly applied to destruction  If you dont understand that fine legitimate criticism Ill write ...   \n",
       "297866.0                                                                                          Ummm The article uses imperial measurements not SI ones Some translation is apparently in order  Anders Törlind   \n",
       "360594.0  I disagree I would leave it out of the introductory part since its population which changes every census is not nearly as fundamental as the fact that it is in a particular state its county seat i...   \n",
       "377054.0  I dont know where you got the idea that Mt Airys in 4 counties Its only in two Were you the one Tokerboy who added two counties to the two Id listed when I put it into the Frederick County article...   \n",
       "661509.0                                                                                                                                                          MarcusAureliusWhy exactly was this user banned    \n",
       "\n",
       "          aggression  attack  toxicity  \n",
       "rev_id                                  \n",
       "37675.0        False   False     False  \n",
       "297866.0       False   False     False  \n",
       "360594.0       False   False     False  \n",
       "377054.0       False   False     False  \n",
       "661509.0       False   False     False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_file_path = \"/content/drive/My Drive/Projects/Freelance/HateClassifier/combined.csv\" if IN_COLAB else \"combined.csv\"\n",
    "combined = pd.read_csv(combined_file_path ,index_col='rev_id')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1548888424113,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "0Clj3xew8KHn",
    "outputId": "683e3ac1-0a72-4c07-fe3e-a81331ddb980"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8899112.0</th>\n",
       "      <td>Leaving aside the fact that it outrageous abuse from the likes of OneGuy and Ta bu shi da yus that drove me to make personal attacks against these characters back when I first started editing  Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308556.0</th>\n",
       "      <td>Stop editing it  Im from Santa Clarita I went to Saugus High School so I know that they are in fact gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9916585.0</th>\n",
       "      <td>Freedom will and must prevail your tyranny will come to an end Nicholas Its looking increasingly likely that blood alone is all that can wash away your sins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10288920.0</th>\n",
       "      <td>but the kilometer of text about the palestinian is not irrelevant to Iraqare the palestinians Iraqi why are so many people are so insistent on beautifying dictators and oppressors living and opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10346963.0</th>\n",
       "      <td>Dear Wikipedia Neutrality guardian Re Saddam Hussein entryno one has yet to answer my question why do the live palestinians deserve mention in the primary intro for a non palestinian leader but th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                            comment\n",
       "rev_id                                                                                                                                                                                                             \n",
       "8899112.0   Leaving aside the fact that it outrageous abuse from the likes of OneGuy and Ta bu shi da yus that drove me to make personal attacks against these characters back when I first started editing  Wik...\n",
       "9308556.0                                                                                                   Stop editing it  Im from Santa Clarita I went to Saugus High School so I know that they are in fact gay\n",
       "9916585.0                                              Freedom will and must prevail your tyranny will come to an end Nicholas Its looking increasingly likely that blood alone is all that can wash away your sins\n",
       "10288920.0  but the kilometer of text about the palestinian is not irrelevant to Iraqare the palestinians Iraqi why are so many people are so insistent on beautifying dictators and oppressors living and opera...\n",
       "10346963.0  Dear Wikipedia Neutrality guardian Re Saddam Hussein entryno one has yet to answer my question why do the live palestinians deserve mention in the primary intro for a non palestinian leader but th..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some only toxic comments\n",
    "combined.comment[(combined.aggression == True) &\n",
    "                 (combined.attack == False) &\n",
    "                 (combined.toxicity == False)].to_frame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiVxY9pm0Uyo"
   },
   "source": [
    "## Prepare the Data\n",
    "Passing our data throughout Spacy's embedding model results in a 300 dimensional vector. Therefore, our **Input** will be a matrix **(m, 300)** and our **Output** will ave the format **(m, 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V7fHWu00Uyl"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "w2v = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2739244,
     "status": "ok",
     "timestamp": 1548537671994,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "JkUey5R-0Uyp",
    "outputId": "8dcd0d85-840b-47be-8c01-1a5829598fd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 77972/77972 [32:09<00:00, 25.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rev_id\n",
       "37675.0     (This, is, not, creative,  , Those, are, the, dictionary, definitions, of, the, terms, insurance, and, ensurance, as, properly, applied, to, destruction,  , If, you, do, nt, understand, that, fine...\n",
       "297866.0                                                                        (Ummm, The, article, uses, imperial, measurements, not, SI, ones, Some, translation, is, apparently, in, order,  , Anders, Törlind)\n",
       "360594.0    (I, disagree, I, would, leave, it, out, of, the, introductory, part, since, its, population, which, changes, every, census, is, not, nearly, as, fundamental, as, the, fact, that, it, is, in, a, pa...\n",
       "377054.0    (I, do, nt, know, where, you, got, the, idea, that, Mt, Airys, in, 4, counties, Its, only, in, two, Were, you, the, one, Tokerboy, who, added, two, counties, to, the, two, I, d, listed, when, I, p...\n",
       "661509.0                                                                                                                                                      (MarcusAureliusWhy, exactly, was, this, user, banned)\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data = combined.comment.progress_apply(w2v)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2658,
     "status": "ok",
     "timestamp": 1548537855300,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "nUTElulV1ALm",
    "outputId": "7ff95b70-8285-4dfd-d8a8-31d7b2b8cea1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675.0</th>\n",
       "      <td>-0.062235</td>\n",
       "      <td>0.106017</td>\n",
       "      <td>-0.165842</td>\n",
       "      <td>-0.022198</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>-0.028963</td>\n",
       "      <td>-0.020820</td>\n",
       "      <td>-0.064699</td>\n",
       "      <td>-0.002372</td>\n",
       "      <td>2.125041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184672</td>\n",
       "      <td>0.048168</td>\n",
       "      <td>-0.040338</td>\n",
       "      <td>-0.062985</td>\n",
       "      <td>0.053665</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>-0.065867</td>\n",
       "      <td>-0.067770</td>\n",
       "      <td>0.051351</td>\n",
       "      <td>0.088927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297866.0</th>\n",
       "      <td>-0.106120</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>-0.081878</td>\n",
       "      <td>-0.003503</td>\n",
       "      <td>-0.050140</td>\n",
       "      <td>0.086373</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>-0.140227</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>1.444926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054261</td>\n",
       "      <td>-0.060219</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>-0.056264</td>\n",
       "      <td>0.220322</td>\n",
       "      <td>-0.013765</td>\n",
       "      <td>-0.066204</td>\n",
       "      <td>-0.132805</td>\n",
       "      <td>0.030887</td>\n",
       "      <td>0.001212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360594.0</th>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.164503</td>\n",
       "      <td>-0.117687</td>\n",
       "      <td>-0.066590</td>\n",
       "      <td>0.081369</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>-0.021676</td>\n",
       "      <td>-0.076261</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>2.354852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182957</td>\n",
       "      <td>0.059658</td>\n",
       "      <td>-0.035043</td>\n",
       "      <td>-0.139206</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>-0.029537</td>\n",
       "      <td>-0.130703</td>\n",
       "      <td>-0.072281</td>\n",
       "      <td>0.041239</td>\n",
       "      <td>0.050962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377054.0</th>\n",
       "      <td>0.048466</td>\n",
       "      <td>0.129485</td>\n",
       "      <td>-0.176208</td>\n",
       "      <td>-0.193257</td>\n",
       "      <td>0.130928</td>\n",
       "      <td>-0.023106</td>\n",
       "      <td>-0.046462</td>\n",
       "      <td>-0.112005</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>2.036610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181011</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>-0.031456</td>\n",
       "      <td>-0.084474</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>-0.130358</td>\n",
       "      <td>-0.045985</td>\n",
       "      <td>-0.067124</td>\n",
       "      <td>0.095851</td>\n",
       "      <td>0.062693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661509.0</th>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.244607</td>\n",
       "      <td>-0.119667</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>-0.136370</td>\n",
       "      <td>0.127092</td>\n",
       "      <td>-0.011563</td>\n",
       "      <td>-0.361178</td>\n",
       "      <td>-0.003496</td>\n",
       "      <td>1.870810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082990</td>\n",
       "      <td>0.026006</td>\n",
       "      <td>0.049182</td>\n",
       "      <td>0.141520</td>\n",
       "      <td>0.128682</td>\n",
       "      <td>-0.111875</td>\n",
       "      <td>-0.219520</td>\n",
       "      <td>0.012039</td>\n",
       "      <td>-0.035978</td>\n",
       "      <td>0.375627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5    \\\n",
       "37675.0  -0.062235  0.106017 -0.165842 -0.022198  0.049608 -0.028963   \n",
       "297866.0 -0.106120  0.025611 -0.081878 -0.003503 -0.050140  0.086373   \n",
       "360594.0  0.008673  0.164503 -0.117687 -0.066590  0.081369  0.003469   \n",
       "377054.0  0.048466  0.129485 -0.176208 -0.193257  0.130928 -0.023106   \n",
       "661509.0  0.024187  0.244607 -0.119667  0.053732 -0.136370  0.127092   \n",
       "\n",
       "               6         7         8         9      ...          290  \\\n",
       "37675.0  -0.020820 -0.064699 -0.002372  2.125041    ...    -0.184672   \n",
       "297866.0  0.012951 -0.140227  0.018732  1.444926    ...    -0.054261   \n",
       "360594.0 -0.021676 -0.076261  0.009957  2.354852    ...    -0.182957   \n",
       "377054.0 -0.046462 -0.112005  0.104653  2.036610    ...    -0.181011   \n",
       "661509.0 -0.011563 -0.361178 -0.003496  1.870810    ...    -0.082990   \n",
       "\n",
       "               291       292       293       294       295       296  \\\n",
       "37675.0   0.048168 -0.040338 -0.062985  0.053665  0.012897 -0.065867   \n",
       "297866.0 -0.060219 -0.034949 -0.056264  0.220322 -0.013765 -0.066204   \n",
       "360594.0  0.059658 -0.035043 -0.139206  0.020856 -0.029537 -0.130703   \n",
       "377054.0  0.045536 -0.031456 -0.084474  0.023443 -0.130358 -0.045985   \n",
       "661509.0  0.026006  0.049182  0.141520  0.128682 -0.111875 -0.219520   \n",
       "\n",
       "               297       298       299  \n",
       "37675.0  -0.067770  0.051351  0.088927  \n",
       "297866.0 -0.132805  0.030887  0.001212  \n",
       "360594.0 -0.072281  0.041239  0.050962  \n",
       "377054.0 -0.067124  0.095851  0.062693  \n",
       "661509.0  0.012039 -0.035978  0.375627  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(lambda x: x.vector)\n",
    "X = pd.DataFrame.from_items(zip(data.index, data.values)).T\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32967,
     "status": "ok",
     "timestamp": 1548537895168,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "BSFhsWfhwOk4",
    "outputId": "2b4f7acd-4274-4c08-c7ee-d64f4ae37ee7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675.0</th>\n",
       "      <td>-0.062235</td>\n",
       "      <td>0.106017</td>\n",
       "      <td>-0.165842</td>\n",
       "      <td>-0.022198</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>-0.028963</td>\n",
       "      <td>-0.020820</td>\n",
       "      <td>-0.064699</td>\n",
       "      <td>-0.002372</td>\n",
       "      <td>2.125041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184672</td>\n",
       "      <td>0.048168</td>\n",
       "      <td>-0.040338</td>\n",
       "      <td>-0.062985</td>\n",
       "      <td>0.053665</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>-0.065867</td>\n",
       "      <td>-0.067770</td>\n",
       "      <td>0.051351</td>\n",
       "      <td>0.088927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297866.0</th>\n",
       "      <td>-0.106120</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>-0.081878</td>\n",
       "      <td>-0.003503</td>\n",
       "      <td>-0.050140</td>\n",
       "      <td>0.086373</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>-0.140227</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>1.444926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054261</td>\n",
       "      <td>-0.060219</td>\n",
       "      <td>-0.034949</td>\n",
       "      <td>-0.056264</td>\n",
       "      <td>0.220322</td>\n",
       "      <td>-0.013765</td>\n",
       "      <td>-0.066204</td>\n",
       "      <td>-0.132805</td>\n",
       "      <td>0.030887</td>\n",
       "      <td>0.001212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360594.0</th>\n",
       "      <td>0.008673</td>\n",
       "      <td>0.164503</td>\n",
       "      <td>-0.117687</td>\n",
       "      <td>-0.066590</td>\n",
       "      <td>0.081369</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>-0.021676</td>\n",
       "      <td>-0.076261</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>2.354852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.182957</td>\n",
       "      <td>0.059658</td>\n",
       "      <td>-0.035043</td>\n",
       "      <td>-0.139206</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>-0.029537</td>\n",
       "      <td>-0.130703</td>\n",
       "      <td>-0.072281</td>\n",
       "      <td>0.041239</td>\n",
       "      <td>0.050962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377054.0</th>\n",
       "      <td>0.048466</td>\n",
       "      <td>0.129485</td>\n",
       "      <td>-0.176208</td>\n",
       "      <td>-0.193257</td>\n",
       "      <td>0.130928</td>\n",
       "      <td>-0.023106</td>\n",
       "      <td>-0.046462</td>\n",
       "      <td>-0.112005</td>\n",
       "      <td>0.104653</td>\n",
       "      <td>2.036610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181011</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>-0.031456</td>\n",
       "      <td>-0.084474</td>\n",
       "      <td>0.023443</td>\n",
       "      <td>-0.130358</td>\n",
       "      <td>-0.045985</td>\n",
       "      <td>-0.067124</td>\n",
       "      <td>0.095851</td>\n",
       "      <td>0.062693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661509.0</th>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.244607</td>\n",
       "      <td>-0.119667</td>\n",
       "      <td>0.053732</td>\n",
       "      <td>-0.136370</td>\n",
       "      <td>0.127092</td>\n",
       "      <td>-0.011563</td>\n",
       "      <td>-0.361178</td>\n",
       "      <td>-0.003496</td>\n",
       "      <td>1.870810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082990</td>\n",
       "      <td>0.026006</td>\n",
       "      <td>0.049182</td>\n",
       "      <td>0.141520</td>\n",
       "      <td>0.128682</td>\n",
       "      <td>-0.111875</td>\n",
       "      <td>-0.219520</td>\n",
       "      <td>0.012039</td>\n",
       "      <td>-0.035978</td>\n",
       "      <td>0.375627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5    \\\n",
       "37675.0  -0.062235  0.106017 -0.165842 -0.022198  0.049608 -0.028963   \n",
       "297866.0 -0.106120  0.025611 -0.081878 -0.003503 -0.050140  0.086373   \n",
       "360594.0  0.008673  0.164503 -0.117687 -0.066590  0.081369  0.003469   \n",
       "377054.0  0.048466  0.129485 -0.176208 -0.193257  0.130928 -0.023106   \n",
       "661509.0  0.024187  0.244607 -0.119667  0.053732 -0.136370  0.127092   \n",
       "\n",
       "               6         7         8         9      ...          290  \\\n",
       "37675.0  -0.020820 -0.064699 -0.002372  2.125041    ...    -0.184672   \n",
       "297866.0  0.012951 -0.140227  0.018732  1.444926    ...    -0.054261   \n",
       "360594.0 -0.021676 -0.076261  0.009957  2.354852    ...    -0.182957   \n",
       "377054.0 -0.046462 -0.112005  0.104653  2.036610    ...    -0.181011   \n",
       "661509.0 -0.011563 -0.361178 -0.003496  1.870810    ...    -0.082990   \n",
       "\n",
       "               291       292       293       294       295       296  \\\n",
       "37675.0   0.048168 -0.040338 -0.062985  0.053665  0.012897 -0.065867   \n",
       "297866.0 -0.060219 -0.034949 -0.056264  0.220322 -0.013765 -0.066204   \n",
       "360594.0  0.059658 -0.035043 -0.139206  0.020856 -0.029537 -0.130703   \n",
       "377054.0  0.045536 -0.031456 -0.084474  0.023443 -0.130358 -0.045985   \n",
       "661509.0  0.026006  0.049182  0.141520  0.128682 -0.111875 -0.219520   \n",
       "\n",
       "               297       298       299  \n",
       "37675.0  -0.067770  0.051351  0.088927  \n",
       "297866.0 -0.132805  0.030887  0.001212  \n",
       "360594.0 -0.072281  0.041239  0.050962  \n",
       "377054.0 -0.067124  0.095851  0.062693  \n",
       "661509.0  0.012039 -0.035978  0.375627  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saves data after w2v\n",
    "X.to_csv('X.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1548538933206,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "uFOVSh5E0Uy7",
    "outputId": "4c9e7c2c-5d2b-4294-ea65-ede7ba7e18fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggression</th>\n",
       "      <th>attack</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297866.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360594.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377054.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661509.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aggression  attack  toxicity\n",
       "rev_id                                \n",
       "37675.0            0       0         0\n",
       "297866.0           0       0         0\n",
       "360594.0           0       0         0\n",
       "377054.0           0       0         0\n",
       "661509.0           0       0         0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target > y\n",
    "y = combined[['aggression', 'attack', 'toxicity']].astype('int')\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ThhBMNOHTO0"
   },
   "outputs": [],
   "source": [
    "# Saves target data\n",
    "y.to_csv('y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtVp_Zg6Noi-"
   },
   "source": [
    "# Machine Learning Models\n",
    "\n",
    "Alright, now that our data is ready we can start to test some models. Starting by some imports from the deep Learning framework used `Pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vuh3My_MnN4s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XtPtNRf-nN4z"
   },
   "source": [
    "Here, we can create a data loader for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDuLZVn6nN44"
   },
   "outputs": [],
   "source": [
    "class HateClassifierDataset(Dataset):\n",
    "    \"\"\"Word 2 Vec of Hate Dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X_csv_file, y_csv_file, normalized=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_csv_file (string): Path to the features csv file.\n",
    "            y_csv_file (string): Path to the target csv file.\n",
    "            normalized (bool): If the features vector will be normalized.\n",
    "        \"\"\"\n",
    "        # Load data\n",
    "        self.features = pd.read_csv(X_csv_file, index_col=0)\n",
    "        self.target = pd.read_csv(y_csv_file, index_col=0)\n",
    "        self.normalized = normalized\n",
    "        \n",
    "        # Normalize features\n",
    "        self.feat_mean = self.features.mean()\n",
    "        self.feat_std = self.features.std()\n",
    "        self.normalized_features = (self.features - self.feat_mean) / self.feat_std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)\n",
    "        \n",
    "        # Normalization\n",
    "        if self.normalized:\n",
    "            vectors = self.normalized_features.iloc[idx, :].values\n",
    "        else:\n",
    "            vectors = self.features.iloc[idx, :].values\n",
    "        \n",
    "        labels = self.target.iloc[idx, :].values\n",
    "        #sample = {'vector': torch.from_numpy(vectors), 'labels': torch.from_numpy(labels)}\n",
    "        \n",
    "        # Convert to tensors\n",
    "        return torch.from_numpy(vectors).float(), torch.from_numpy(labels).float()\n",
    "\n",
    "# Create Datasets \n",
    "X_file_path = \"/content/drive/My Drive/Projects/Freelance/HateClassifier/X.csv\" if IN_COLAB else \"X.csv\"\n",
    "y_file_path = \"/content/drive/My Drive/Projects/Freelance/HateClassifier/y.csv\" if IN_COLAB else \"y.csv\"\n",
    "dataset = HateClassifierDataset(X_file_path,\n",
    "                                y_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5989,
     "status": "ok",
     "timestamp": 1548888611055,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "1Oy2C3G-nN5G",
    "outputId": "68ea3b79-ab4f-499f-ab93-da60d1700d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([300]) torch.Size([3])\n",
      "1 torch.Size([300]) torch.Size([3])\n",
      "2 torch.Size([300]) torch.Size([3])\n",
      "3 torch.Size([300]) torch.Size([3])\n",
      "77972\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "for i in range(4):\n",
    "    features, target = dataset[i]\n",
    "    print(i, features.size(), target.size())\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgqqQ4fKnN5M"
   },
   "source": [
    "Additionally, we can create a `DataLoader` that will take care of creating the batch size, shuffling and parallelism. We also divide our data in train/dev. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9Z2YOignN5N"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "train_dev_ratio = 0.8\n",
    "batch_size = 128\n",
    "\n",
    "# Split data\n",
    "train_size = int(train_dev_ratio * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, dev_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Data Loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 756,
     "status": "ok",
     "timestamp": 1548888627493,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "w7nIfvExnN5X",
    "outputId": "eb279ac8-c0e2-4348-8def-cd7a156ba7e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([128, 300]) torch.Size([128, 3]) tensor(0.0030) tensor(0.9527)\n",
      "1 torch.Size([128, 300]) torch.Size([128, 3]) tensor(0.0019) tensor(0.9982)\n",
      "2 torch.Size([128, 300]) torch.Size([128, 3]) tensor(0.0015) tensor(1.0373)\n",
      "3 torch.Size([128, 300]) torch.Size([128, 3]) tensor(-0.0121) tensor(0.9934)\n",
      "4 torch.Size([128, 300]) torch.Size([128, 3]) tensor(0.0024) tensor(1.0455)\n",
      "5 torch.Size([128, 300]) torch.Size([128, 3]) tensor(-0.0045) tensor(0.9523)\n",
      "Number of batches on train: 488\n",
      "Number of batches on test: 122\n"
     ]
    }
   ],
   "source": [
    "# Test Data Loader\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print(i_batch, sample_batched[0].size(),\n",
    "          sample_batched[1].size(),\n",
    "          torch.mean(sample_batched[0]),\n",
    "          torch.std(sample_batched[0]))\n",
    "    if i_batch == 5:\n",
    "        break\n",
    "\n",
    "print(\"Number of batches on train: {}\".format(len(train_loader)))\n",
    "print(\"Number of batches on test: {}\".format(len(dev_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yCiAyvF0nN5d"
   },
   "source": [
    "The first model tested will be a simple multi-layer Neural Network using **Pytorch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ws39eeB0nN5f"
   },
   "outputs": [],
   "source": [
    "# Network Class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nodes_in = 300, nodes_out = 3, nodes_hidden = [64, 32],\n",
    "                 drop_prob=.5, batch_norm=True):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Model architecture\n",
    "        self.batch_norm = batch_norm\n",
    "        self.nodes_in = nodes_in\n",
    "        self.nodes_hidden = nodes_hidden\n",
    "        self.nodes_out = nodes_out\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # Input Layer\n",
    "        self.fc1 = nn.Linear(nodes_in, nodes_hidden[0])\n",
    "        \n",
    "        # Hidden Layers\n",
    "        for i in range(len(nodes_hidden) - 1):\n",
    "            setattr(self, 'fc' + str(i + 2),\n",
    "                    nn.Linear(nodes_hidden[i], nodes_hidden[i + 1]))\n",
    "            setattr(self, 'bn' + str(i + 1),\n",
    "                    nn.BatchNorm1d(nodes_hidden[i]))\n",
    "        # Output Layer\n",
    "        setattr(self, 'fc' + str(len(nodes_hidden) + 1),\n",
    "                nn.Linear(nodes_hidden[-1], nodes_out))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        for i in range(len(self.nodes_hidden) - 1):\n",
    "          if self.batch_norm:\n",
    "            x = getattr(self, 'bn' + str(i + 1))(x)\n",
    "          x = self.dropout(x)\n",
    "          x = F.relu(getattr(self, 'fc' + str(i + 2))(x))\n",
    "          \n",
    "        x = self.dropout(x)\n",
    "        x = getattr(self, 'fc' + str(len(self.nodes_hidden) + 1))(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1548888648351,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "P7nbtZilnN5r",
    "outputId": "7f97522a-4579-4b49-9495-35be65b2f87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc1): Linear(in_features=300, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 773,
     "status": "ok",
     "timestamp": 1548888652707,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "Aet5rgJnnN5x",
    "outputId": "d2ef3fe1-792a-4ba9-d7b4-aae1a0b430fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21571"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainable parametes\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlv2NYjOnN52"
   },
   "source": [
    "# Train network\n",
    "\n",
    "Our model is finally ready to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1548888686084,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "oXlgPXHUpgcZ",
    "outputId": "e78a5f8a-9c38-455a-d905-81a2f1880017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available!\n"
     ]
    }
   ],
   "source": [
    "# Check for gpu\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(\"Cuda available!\" if use_gpu else \"Cuda not available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-6u-NbXnN53"
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Loss for multilabel problem (applies sigmoid within)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "# Move model to Cuda if available\n",
    "if use_gpu:\n",
    "  net.cuda()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9C6DBaKVjlE"
   },
   "outputs": [],
   "source": [
    "def predict_probs(model, inputs):\n",
    "  \"\"\"\n",
    "  Convert model outputs to prediction probabilities.\n",
    "  \n",
    "  Arg:\n",
    "    model: Model used.\n",
    "  \n",
    "  Return:\n",
    "    prob: Tensor (1, 3) that represents probabilities for the 3 classes.\n",
    "  \"\"\"\n",
    "  # Forward pass\n",
    "  with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "  \n",
    "  # Probabilities\n",
    "  probs = torch.sigmoid(logits)\n",
    "  \n",
    "  return probs.cpu().numpy()\n",
    "\n",
    "\n",
    "def test_model(model, dev_loader, use_gpu=True):\n",
    "  \"\"\"\n",
    "  Tests the model on development dataset.\n",
    "  \n",
    "  Args: \n",
    "    model: Model to be analysed.\n",
    "    dev_loader: Dataloader for the dev dataset.\n",
    "    use_gpu: If the GPU is beiing used.\n",
    "    \n",
    "  Return:\n",
    "    Returns model accuracy.\n",
    "  \"\"\"\n",
    "  # Initialize metrics\n",
    "  total = 0\n",
    "  # Evaluate mode\n",
    "  model.eval()\n",
    "  \n",
    "  # No gradients for speedup\n",
    "  with torch.no_grad():\n",
    "    for i, data in enumerate(dev_loader, 0):\n",
    "          # get the inputs\n",
    "          inputs, labels = data[0], data[1]\n",
    "          if use_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "          if i==0:\n",
    "            correct_per_class = np.zeros(labels.size()[1])\n",
    "          # Get prediction\n",
    "          probs = predict_probs(model, inputs)\n",
    "          pred = probs >= .5\n",
    "\n",
    "          # Correct preictions\n",
    "          labels_numpy = labels.cpu().numpy()\n",
    "          correct_per_class += np.sum(labels_numpy == pred, axis=0)\n",
    "          total += labels_numpy.shape[0]\n",
    "\n",
    "  # Overall accuracy and for each class\n",
    "  overall_acc = np.sum(correct_per_class) / (total * correct_per_class.shape[0])\n",
    "  class_acc = correct_per_class / total\n",
    "  \n",
    "  # Return to train mode\n",
    "  model.train()\n",
    "  return class_acc, overall_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1149248,
     "status": "ok",
     "timestamp": 1548889898245,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "m9ot2PBNnN56",
    "outputId": "8956e24c-40a2-4a9c-9b08-6d21d7ec5655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.328\n",
      "[2,   300] loss: 0.235\n",
      "[3,   300] loss: 0.226\n",
      "[4,   300] loss: 0.224\n",
      "[5,   300] loss: 0.216\n",
      "[6,   300] loss: 0.218\n",
      "[7,   300] loss: 0.214\n",
      "[8,   300] loss: 0.213\n",
      "[9,   300] loss: 0.210\n",
      "[10,   300] loss: 0.208\n",
      "Model Saved Successfully!\n",
      "Overall Accuracy: 0.9217911723843112\n",
      "Class Accuracy: [0.91542161 0.92516832 0.92478358]\n",
      "[11,   300] loss: 0.206\n",
      "[12,   300] loss: 0.204\n",
      "[13,   300] loss: 0.205\n",
      "[14,   300] loss: 0.205\n",
      "[15,   300] loss: 0.204\n",
      "[16,   300] loss: 0.203\n",
      "[17,   300] loss: 0.199\n",
      "[18,   300] loss: 0.199\n",
      "[19,   300] loss: 0.200\n",
      "[20,   300] loss: 0.198\n",
      "Overall Accuracy: 0.921470556802394\n",
      "Class Accuracy: [0.91599872 0.92523245 0.92318051]\n",
      "[21,   300] loss: 0.200\n",
      "[22,   300] loss: 0.198\n",
      "[23,   300] loss: 0.198\n",
      "[24,   300] loss: 0.197\n",
      "[25,   300] loss: 0.201\n",
      "[26,   300] loss: 0.197\n",
      "[27,   300] loss: 0.198\n",
      "[28,   300] loss: 0.193\n",
      "[29,   300] loss: 0.196\n",
      "[30,   300] loss: 0.196\n",
      "Overall Accuracy: 0.9212354387089879\n",
      "Class Accuracy: [0.91606284 0.92491183 0.92273164]\n",
      "[31,   300] loss: 0.194\n",
      "[32,   300] loss: 0.194\n",
      "[33,   300] loss: 0.194\n",
      "[34,   300] loss: 0.194\n",
      "[35,   300] loss: 0.192\n",
      "[36,   300] loss: 0.195\n",
      "[37,   300] loss: 0.191\n",
      "[38,   300] loss: 0.193\n",
      "[39,   300] loss: 0.192\n",
      "[40,   300] loss: 0.191\n",
      "Overall Accuracy: 0.9215560542909053\n",
      "Class Accuracy: [0.91542161 0.92587368 0.92337288]\n",
      "[41,   300] loss: 0.191\n",
      "[42,   300] loss: 0.189\n",
      "[43,   300] loss: 0.192\n",
      "[44,   300] loss: 0.191\n",
      "[45,   300] loss: 0.191\n",
      "[46,   300] loss: 0.192\n",
      "[47,   300] loss: 0.189\n",
      "[48,   300] loss: 0.188\n",
      "[49,   300] loss: 0.190\n",
      "[50,   300] loss: 0.189\n",
      "Overall Accuracy: 0.9217697980121834\n",
      "Class Accuracy: [0.91606284 0.92484771 0.92439885]\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "print_every = 300   # number of minibatches to show loss progress\n",
    "dev_accuracy = 10    # number of epochs to show dev accuracy\n",
    "best_accuracy = 0   # best accuracy\n",
    "epochs = 50\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    # Initilize losses\n",
    "    running_loss = 0.0\n",
    "    # Network in train mode\n",
    "    net.train()\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data[0], data[1]\n",
    "        if use_gpu:\n",
    "          inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_every == print_every - 1:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / print_every))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Test on devset\n",
    "    if epoch % dev_accuracy == dev_accuracy - 1:\n",
    "        class_acc, overall_acc = test_model(net, dev_loader, use_gpu=True)\n",
    "        \n",
    "        # Saves model with good result in devset\n",
    "        if overall_acc > best_accuracy:\n",
    "          best_accuracy = overall_acc\n",
    "          net.optimizer_state = optimizer.state_dict()\n",
    "          save_model(net, 'best_model')\n",
    "        print('Overall Accuracy: {}'.format(overall_acc))\n",
    "        print('Class Accuracy: {}'.format(class_acc))\n",
    "       \n",
    "# Saves optimizer state\n",
    "net.optimizer_state = optimizer.state_dict()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0rQ6okNnN6B"
   },
   "outputs": [],
   "source": [
    "def save_model(model, file_name=\"checkpoint\"):\n",
    "    \"\"\"\n",
    "    Saves the given model with all the needed info.\n",
    "\n",
    "    Args: \n",
    "        model: Model to be saved.\n",
    "        file_name: initial file name of the saved model.\n",
    "    \"\"\"\n",
    "    # Saves model \n",
    "    checkpoint = {'batch_norm': model.batch_norm,\n",
    "                  'nodes_in': model.nodes_in,\n",
    "                  'nodes_hidden': model.nodes_hidden,\n",
    "                  'nodes_out': model.nodes_out,\n",
    "                  'prop_prob': model.drop_prob,\n",
    "                  'optimizer_state': model.optimizer_state,\n",
    "                  'state_dict': model.state_dict()}\n",
    "\n",
    "    torch.save(checkpoint, file_name + '.pth')\n",
    "    print(\"Model Saved Successfully!\")\n",
    "#save_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 974,
     "status": "ok",
     "timestamp": 1548887070974,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "PAs03EpPirVk",
    "outputId": "048952f6-44c6-4ec4-c2d9-b6a4f26c93fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (fc1): Linear(in_features=300, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(file_name):\n",
    "  \"\"\"\n",
    "  Return saved model in file_name.\n",
    "  \n",
    "  Args: \n",
    "    file_name: Name of the file to load the model from.\n",
    "    \n",
    "  Return:\n",
    "    model: the model.\n",
    "  \"\"\"\n",
    "  # Load data\n",
    "  checkpoint = torch.load(file_name, map_location='cpu')\n",
    "  \n",
    "  # Initialize model and optimizer\n",
    "  model = Net(checkpoint['nodes_in'], checkpoint['nodes_out'],\n",
    "              checkpoint['nodes_hidden'], checkpoint['prop_prob'],\n",
    "              checkpoint['batch_norm'])\n",
    "  criterion = nn.BCEWithLogitsLoss()  # Loss for multilabel problem (applies sigmoid within)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "  # Recover states\n",
    "  model.load_state_dict(checkpoint['state_dict'])\n",
    "  model.eval()\n",
    "  \n",
    "  return model\n",
    "\n",
    "net = load_model('best_model.pth')\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 979,
     "status": "ok",
     "timestamp": 1548892455729,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "Orv6BClRRCnJ",
    "outputId": "ad1f549f-6122-49ea-b811-88f14b93c630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00518467, 0.00311299, 0.00389021], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, text_input, w2v, dataset):\n",
    "  \"\"\"\n",
    "  Predicts the text using the input model.\n",
    "  \n",
    "  Args:\n",
    "    model: model used for prediction.\n",
    "    text_inputs: string with the text input.\n",
    "  \"\"\"\n",
    "  # Cleans input\n",
    "  clean_text = re.sub(r'[^\\w\\s]','', text_input)\n",
    "  \n",
    "  # Applies word to vector embedding\n",
    "  vector = w2v(clean_text).vector\n",
    "  normed_vector = (vector - dataset.feat_mean) / dataset.feat_std\n",
    "  inputs = torch.unsqueeze(torch.tensor(normed_vector), dim=0)\n",
    "  \n",
    "  # Uses model\n",
    "  model.eval()   # Evaluation mode\n",
    "  model.cpu()    # Move to cpu\n",
    "  \n",
    "  # Probabilities\n",
    "  probs = predict_probs(model, inputs).squeeze()\n",
    "  \n",
    "  return probs\n",
    "\n",
    "# text = \"It is a beautiful day outside\"\n",
    "# text = \"FUCK YOU!!!!\"\n",
    "# text = \"You are a complete moron\"\n",
    "text = \"I wish you a lovely week!!!!!\"\n",
    "\n",
    "predict(net, text, w2v, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1548892767284,
     "user": {
      "displayName": "Fernando Henrique",
      "photoUrl": "https://lh3.googleusercontent.com/-de_sypvROCI/AAAAAAAAAAI/AAAAAAABAOE/rYXXyUHtDCw/s64/photo.jpg",
      "userId": "12801630509008055089"
     },
     "user_tz": 180
    },
    "id": "g-ywlP4OqtaV",
    "outputId": "d6161532-5f72-4ad1-8e4b-425ffa53e94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48997894 0.46892837 0.5104517 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('dark')\n",
    "def print_probs(model, text, w2v, dataset):\n",
    "  \"\"\"\n",
    "  Plots the results.\n",
    "  \n",
    "  Args:\n",
    "    model: Model used.\n",
    "    text: text to generate the probabilities.\n",
    "    w2v: embedding model.\n",
    "    dataset: dataset class.\n",
    "  \"\"\"\n",
    "  # Calculate Probs\n",
    "  values = predict(net, text, w2v, dataset)\n",
    "  print(values)\n",
    "  x = [\"Agressiveness\", \"Direct Attack\", \"Toxicity\"]\n",
    "  \n",
    "  # plt.bar(x, values)\n",
    "\n",
    "  threshold = 0.5\n",
    "\n",
    "  # split it up\n",
    "  above_threshold = np.maximum(values - threshold, 0)\n",
    "  below_threshold = np.minimum(values, threshold)\n",
    "\n",
    "  # and plot it\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.bar(x, below_threshold, 0.35, color=\"blue\")\n",
    "  ax.bar(x, above_threshold, 0.35, color=\"red\",\n",
    "         bottom=below_threshold)\n",
    "  \n",
    "  # horizontal line indicating the threshold\n",
    "  ax.plot([0., len(x) - 1], [threshold, threshold], \"k--\")\n",
    "  ax.set_ylim([0, 1])\n",
    "  ax.set_title(text)\n",
    "  \n",
    "text = \"I am worthless person deep inside\"\n",
    "# text = \"F*CK YOU!!!!\"\n",
    "# text = \"You are a completely crazy, but I love you.\"\n",
    "# text = \"Sorry. I could not understand what you said. I am so dumb.\"\n",
    "print_probs(net, text, w2v, dataset)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1g5qHBAJvPUk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DataAnalysis.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
